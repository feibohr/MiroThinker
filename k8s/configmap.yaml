---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mirothinker-config
  namespace: chat
data: 
  # LLM Configuration
  SERPER_API_KEY: "3b26148c7cd645f2d6fba8015c74aa886f0fa5cb"
  SERPER_BASE_URL: "https://google.serper.dev"

  # API for Web Scraping (recommend)
  JINA_API_KEY: "jina_8f0f9fc9cfe748be9f99472ab7229ad7Yrb5d_D15F3Y32__AfdN4S70jbNl"
  JINA_BASE_URL: "https://r.jina.ai"

  # API for Linux Sandbox (recommend)
  E2B_API_KEY: "e2b_9ba4456795ffafc22ad6e02f59dac27cd1f9b45c"

  # API for LLM-as-Judge (for benchmark testing)
  #OPENAI_API_KEY: "your_openai_key"
  #OPENAI_BASE_URL: "https://api.openai.com/v1"

  # API for Open-Source Audio Transcription Tool (for benchmark testing)
  #WHISPER_MODEL_NAME: "openai/whisper-large-v3-turbo"
  #WHISPER_API_KEY: "your_whisper_key"
  #WHISPER_BASE_URL: "https://your_whisper_base_url/v1"

  # API for Open-Source VQA Tool (for benchmark testing)
  VISION_MODEL_NAME: "qwen/qwen3-vl-235b-a22b-instruct"
  VISION_API_KEY: "7k8PRHTyJw8sRMos5HLz8misfdkklfdf"
  VISION_BASE_URL: "https://gpt.sinohealth.com/v2/openai/chat/completions"

  # API for Open-Source Reasoning Tool (for benchmark testing)
  REASONING_MODEL_NAME: "mirothinker"
  REASONING_API_KEY: "7k8PRHTyJw8sRMos5HLz8misfdkklfdf"
  REASONING_BASE_URL: "http://192.168.56.67:17001/v1"

  # API for Claude Sonnet 3.7 as Commercial Tools (optional)
  #ANTHROPIC_API_KEY: "your_anthropic_key"
  #ANTHROPIC_BASE_URL: "https://api.anthropic.com"

  # API for Sogou Search (optional)
  TENCENTCLOUD_SECRET_ID: ""
  TENCENTCLOUD_SECRET_KEY: ""

  # API for Summary LLM (optional)
  SUMMARY_LLM_BASE_URL: "http://192.168.56.67:17001/v1"
  SUMMARY_LLM_MODEL_NAME: "mirothinker"
  SUMMARY_LLM_API_KEY: "7k8PRHTyJw8sRMos5HLz8misfdkklfdf"
  
  # Base LLM Configuration (required for Docker Compose)
  BASE_URL: "http://192.168.56.67:17001/v1"
  API_KEY: "eyJhbGciOiJIUzI1NiIs"
  DEFAULT_MODEL_NAME: "mirothinker"
  DEFAULT_LLM_PROVIDER: "qwen"
  DEFAULT_AGENT_SET: "demo"

  # Logging
  LOG_DIR: "/app/logs"
  DEMO_MODE: "1"

  # Port Configuration
  PORT: "7860"
  API_PORT: "8000"
  GRADIO_PORT: "7860"

  # Concurrency Configuration
  PIPELINE_POOL_SIZE: "5"
  MAX_CONCURRENT_REQUESTS: "10"

  # Context Management
  CONTEXT_COMPRESSION_ENABLED: "true"
  MAX_HISTORY_TOKENS: "30000"
